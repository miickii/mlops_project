Here is my current code files:

dataset.py:
import torch
from torch.utils.data import Dataset, DataLoader

class FruitsDataset(Dataset):
    """
    Custom Dataset for loading preprocessed tensors with optional transformations.
    """
    def __init__(self, images, labels, transform=None):
        """
        Args:
            images (Tensor): Tensor containing image data.
            labels (Tensor): Tensor containing labels.
            transform (callable, optional): Optional transform to apply to the images.
        """
        self.images = images
        self.labels = labels
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        image = self.images[idx]
        label = self.labels[idx]

        # Apply transformations, if any
        if self.transform:
            image = self.transform(image)

        return image, label


def get_dataloaders(train_image_file, train_target_file, test_image_file, test_target_file, batch_size=32, transform=None):
    """
    Load preprocessed data and return DataLoaders for training and testing.

    Args:
        train_image_file (str): Path to training images tensor (.pt file).
        train_target_file (str): Path to training labels tensor (.pt file).
        test_image_file (str): Path to testing images tensor (.pt file).
        test_target_file (str): Path to testing labels tensor (.pt file).
        batch_size (int): Batch size for DataLoader.
        transform (callable, optional): Transform to apply to the images.

    Returns:
        tuple: Train and test DataLoaders.
    """
    # Load tensors
    train_images = torch.load(train_image_file)
    train_targets = torch.load(train_target_file)
    test_images = torch.load(test_image_file)
    test_targets = torch.load(test_target_file)

    # Create datasets
    train_dataset = FruitsDataset(train_images, train_targets, transform=transform)
    test_dataset = FruitsDataset(test_images, test_targets, transform=transform)

    # Create DataLoaders
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

    return train_loader, test_loader

model.py:
import timm
import torch
from torch import nn
from torchinfo import summary

def ProjectModel(num_classes, pretrained=True):
    """
    Create and configure the model.
    
    Args:
        num_classes (int): Number of output classes.
        pretrained (bool): Whether to use a pretrained model.

    Returns:
        torch.nn.Module: Configured model.
    """
    if num_classes <= 0:
        raise ValueError("Number of classes must be greater than zero.")

    # Load pretrained ResNet
    model = timm.create_model("resnet18", pretrained=pretrained)

    # Modify the final layer to match the number of classes
    model.fc = nn.Linear(model.fc.in_features, num_classes)

    return model

if __name__ == "__main__":
    num_classes = 141
    model = ProjectModel(num_classes)
    summary(model, input_size=(1, 3, 100, 100))

    dummy_input = torch.randn(1, 3, 100, 100)
    model.eval()
    with torch.no_grad():
        output = model(dummy_input)

    print(f"Output shape: {output.shape}")

train.py:
from mlops_project.dataset import get_dataloaders
from mlops_project.model import ProjectModel
import torch
from torch import nn, optim
from tqdm import tqdm
import os
import argparse

def train_model(train_loader, model, criterion, optimizer, device, epochs=4, model_name="model.pth"):
    for epoch in range(epochs):
        model.train()
        train_loss, correct, total = 0, 0, 0

        with tqdm(train_loader, desc=f"Epoch {epoch+1}/{epochs}", unit="batch") as pbar:
            for images, labels in pbar:
                images, labels = images.to(device), labels.to(device)

                outputs = model(images)
                loss = criterion(outputs, labels)

                optimizer.zero_grad()
                loss.backward()
                optimizer.step()

                train_loss += loss.item()
                _, predicted = outputs.max(1)
                total += labels.size(0)
                correct += predicted.eq(labels).sum().item()

                pbar.set_postfix({
                    "loss": f"{train_loss / total:.4f}",
                    "accuracy": f"{100. * correct / total:.2f}%"
                })

        print(f"Epoch {epoch+1}/{epochs}, Loss: {train_loss/len(train_loader):.4f}, Accuracy: {100.*correct/total:.2f}%")
    
    # Save the model
    checkpoint_path = os.path.join("models/", model_name)
    torch.save({
        'epoch': epoch + 1,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'loss': train_loss / len(train_loader),
    }, checkpoint_path)
    print(f"Model saved to {checkpoint_path}")

# eksempel script: train --epochs 20 --batch_size 128
def main():
    parser = argparse.ArgumentParser(description="Train a fruit classification model.")
    parser.add_argument("--epochs", type=int, default=4, help="Number of training epochs (default: 4)")
    parser.add_argument("--batch_size", type=int, default=32, help="Batch size for training (default: 32)")
    parser.add_argument("--lr", type=float, default=1e-4, help="Learning rate for optimizer (default: 1e-4)")
    parser.add_argument("--model_name", type=str, default="model.pth", help="Filename for saving the trained model (default: model.pth)")

    args = parser.parse_args()

    train_image_file = "data/processed/train_images.pt"
    train_target_file = "data/processed/train_targets.pt"
    test_image_file = "data/processed/test_images.pt"
    test_target_file = "data/processed/test_targets.pt"

    train_loader, _ = get_dataloaders(
        train_image_file, train_target_file, test_image_file, test_target_file, batch_size=args.batch_size, transform=None
    )

    num_classes = 141
    model = ProjectModel(num_classes=num_classes)
    device = torch.device("cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu")
    model.to(device)

    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=args.lr)

    train_model(train_loader, model, criterion, optimizer, device, epochs=args.epochs, model_name=args.model_name)


if __name__ == "__main__":
    train_image_file = "data/processed/train_images.pt"
    train_target_file = "data/processed/train_targets.pt"
    test_image_file = "data/processed/test_images.pt"
    test_target_file = "data/processed/test_targets.pt"

    # No normalization transform since preprocessing already handled it
    train_loader, test_loader = get_dataloaders(
        train_image_file, train_target_file, test_image_file, test_target_file, batch_size=32, transform=None
    )

    num_classes = 141
    model = ProjectModel(num_classes=num_classes)
    device = torch.device("cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu")
    model.to(device)

    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=1e-4)

    train_model(train_loader, model, criterion, optimizer, device, epochs=4)

evaluate.py:
from mlops_project.dataset import get_dataloaders
from mlops_project.model import ProjectModel
import torch
from torch.utils.data import DataLoader
import typer

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu")

def evaluate(model_checkpoint: str, batch_size: int = 32) -> None:
    print("Starting evaluation...")

    train_image_file = "data/processed/train_images.pt"
    train_target_file = "data/processed/train_targets.pt"
    test_image_file = "data/processed/test_images.pt"
    test_target_file = "data/processed/test_targets.pt"

    _, test_loader = get_dataloaders(
        train_image_file, train_target_file, test_image_file, test_target_file, batch_size=batch_size, transform=None
    )

    print("Loading model...")
    num_classes = 141
    model = ProjectModel(num_classes=num_classes)

    # Load the saved model state_dict from the checkpoint
    checkpoint = torch.load(model_checkpoint, map_location=DEVICE)
    model.load_state_dict(checkpoint['model_state_dict'])  # Correctly load the model parameters
    model.to(DEVICE)

    model.eval()
    test_loss, correct, total = 0, 0, 0
    criterion = torch.nn.CrossEntropyLoss()

    print("Evaluating model...")
    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(DEVICE), labels.to(DEVICE)
            outputs = model(images)
            loss = criterion(outputs, labels)

            test_loss += loss.item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

    accuracy = 100. * correct / total
    print(f"Test Loss: {test_loss / len(test_loader):.4f}")
    print(f"Test Accuracy: {accuracy:.2f}%")

# kør script: evaluate "models/model.pth" --batch-size 32
def main():
    typer.run(evaluate)

if __name__ == "__main__":
    typer.run(evaluate)
    # python evaluate.py "models/model.pth"


visualize.py:
import matplotlib.pyplot as plt
import torch
import typer
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from mlops_project.dataset import get_dataloaders
from mlops_project.model import ProjectModel

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu")

def visualize(
    model_checkpoint: str,
    figure_name: str = "embeddings.png",
    batch_size: int = 32
) -> None:
    """
    Visualize model embeddings using t-SNE.

    Args:
        model_checkpoint (str): Path to the trained model checkpoint.
        figure_name (str): Name of the output visualization file.
        batch_size (int): Batch size for DataLoader.
    """
    print("Starting visualization...")

    # Load test data using get_dataloaders()
    train_image_file = "data/processed/train_images.pt"
    train_target_file = "data/processed/train_targets.pt"
    test_image_file = "data/processed/test_images.pt"
    test_target_file = "data/processed/test_targets.pt"

    _, test_loader = get_dataloaders(
        train_image_file, train_target_file, test_image_file, test_target_file, batch_size=batch_size, transform=None
    )

    print("Loading model...")
    num_classes = 141
    model = ProjectModel(num_classes=num_classes)

    # Load the saved model state_dict from the checkpoint
    checkpoint = torch.load(model_checkpoint, map_location=DEVICE)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.to(DEVICE)

    # Replace the final fully connected layer with an identity layer for embeddings
    model.fc = torch.nn.Identity()
    model.eval()

    print("Extracting embeddings...")
    embeddings, targets = [], []
    with torch.no_grad():
        for images, labels in test_loader:
            images = images.to(DEVICE)
            outputs = model(images)
            embeddings.append(outputs.cpu())
            targets.append(labels)

    embeddings = torch.cat(embeddings).numpy()
    targets = torch.cat(targets).numpy()

    # Reduce dimensionality if needed
    if embeddings.shape[1] > 500:
        print("Reducing dimensionality using PCA...")
        pca = PCA(n_components=100)
        embeddings = pca.fit_transform(embeddings)

    print("Applying t-SNE for 2D visualization...")
    tsne = TSNE(n_components=2, random_state=42)
    embeddings_2d = tsne.fit_transform(embeddings)

    print("Generating visualization...")
    plt.figure(figsize=(10, 10))
    unique_labels = set(targets)
    for label in unique_labels:
        mask = targets == label
        plt.scatter(embeddings_2d[mask, 0], embeddings_2d[mask, 1], label=str(label), alpha=0.7)

    plt.legend(title="Classes")
    plt.title("t-SNE Visualization of Test Embeddings")
    plt.xlabel("Dimension 1")
    plt.ylabel("Dimension 2")
    plt.savefig(f"reports/figures/{figure_name}")
    print(f"Visualization saved as {figure_name}")

# visualize "models/model.pth" --figure-name "embedding_visualization.png" --batch-size 64
def main():
    typer.run(visualize)

if __name__ == "__main__":
    typer.run(visualize)
    # Eksempel på command: python visualize.py "models/model.pth" "data/processed/test_images.pt" "data/processed/test_targets.pt" --figure-name="embedding_visualization.png" --batch-size=64

Also here is pyproject.toml:
[build-system]
requires = ["setuptools"]
build-backend = "setuptools.build_meta"

[project]
name = "mlops_project"
version = "0.0.1"
description = "MLOps project"
authors = [
  { name = "JMW", email = "your@email.com" },
]

keywords = ["machine learning", "MLOps"]
classifiers = [
  "Development Status :: 3 - Alpha",
  "Programming Language :: Python :: 3",
]
readme = "README.md"
requires-python = ">=3.11"
dynamic = ["dependencies", "optional-dependencies"]

[tool.setuptools.dynamic]
dependencies = {file = ["requirements.txt"]}

[tool.setuptools.dynamic.optional-dependencies]
dev = {file = ['requirements_dev.txt']}

[tool.ruff]
line-length = 120

[tool.coverage.run]
omit = ["tests/*"]

[project.scripts]
train = "mlops_project.train:main"
evaluate = "mlops_project.evaluate:main"
visualize = "mlops_project.visualize:main"